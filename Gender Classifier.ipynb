{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.naive_bayes as nb\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./names.zip') as file:\n",
    "    file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.genfromtxt('../Datasets ML/yob2019.txt',dtype='str',delimiter=',')\n",
    "names=data[:,0]\n",
    "y=pd.get_dummies(data[:,1],drop_first=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SyllableTokenizer in module nltk.tokenize.sonority_sequencing:\n",
      "\n",
      "class SyllableTokenizer(nltk.tokenize.api.TokenizerI)\n",
      " |  SyllableTokenizer(lang='en', sonority_hierarchy=False)\n",
      " |  \n",
      " |  Syllabifies words based on the Sonority Sequencing Principle (SSP).\n",
      " |  \n",
      " |      >>> from nltk.tokenize import SyllableTokenizer\n",
      " |      >>> from nltk import word_tokenize\n",
      " |      >>> SSP = SyllableTokenizer()\n",
      " |      >>> SSP.tokenize('justification')\n",
      " |      ['jus', 'ti', 'fi', 'ca', 'tion']\n",
      " |      >>> text = \"This is a foobar-like sentence.\"\n",
      " |      >>> [SSP.tokenize(token) for token in word_tokenize(text)]\n",
      " |      [['This'], ['is'], ['a'], ['foo', 'bar', '-', 'li', 'ke'], ['sen', 'ten', 'ce'], ['.']]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SyllableTokenizer\n",
      " |      nltk.tokenize.api.TokenizerI\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, lang='en', sonority_hierarchy=False)\n",
      " |      :param lang: Language parameter, default is English, 'en'\n",
      " |      :type lang: str\n",
      " |      :param sonority_hierarchy: Sonority hierarchy according to the\n",
      " |                                 Sonority Sequencing Principle.\n",
      " |      :type sonority_hierarchy: list(str)\n",
      " |  \n",
      " |  assign_values(self, token)\n",
      " |      Assigns each phoneme its value from the sonority hierarchy.\n",
      " |      Note: Sentence/text has to be tokenized first.\n",
      " |      \n",
      " |      :param token: Single word or token\n",
      " |      :type token: str\n",
      " |      :return: List of tuples, first element is character/phoneme and\n",
      " |               second is the soronity value.\n",
      " |      :rtype: list(tuple(str, int))\n",
      " |  \n",
      " |  tokenize(self, token)\n",
      " |      Apply the SSP to return a list of syllables.\n",
      " |      Note: Sentence/text has to be tokenized first.\n",
      " |      \n",
      " |      :param token: Single word or token\n",
      " |      :type token: str\n",
      " |      :return syllable_list: Single word or token broken up into syllables.\n",
      " |      :rtype: list(str)\n",
      " |  \n",
      " |  validate_syllables(self, syllable_list)\n",
      " |      Ensures each syllable has at least one vowel.\n",
      " |      If the following syllable doesn't have vowel, add it to the current one.\n",
      " |      \n",
      " |      :param syllable_list: Single word or token broken up into syllables.\n",
      " |      :type syllable_list: list(str)\n",
      " |      :return: Single word or token broken up into syllables\n",
      " |               (with added syllables if necessary)\n",
      " |      :rtype: list(str)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.tokenize.api.TokenizerI:\n",
      " |  \n",
      " |  span_tokenize(self, s)\n",
      " |      Identify the tokens using integer offsets ``(start_i, end_i)``,\n",
      " |      where ``s[start_i:end_i]`` is the corresponding token.\n",
      " |      \n",
      " |      :rtype: iter(tuple(int, int))\n",
      " |  \n",
      " |  span_tokenize_sents(self, strings)\n",
      " |      Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:\n",
      " |      \n",
      " |          return [self.span_tokenize(s) for s in strings]\n",
      " |      \n",
      " |      :rtype: iter(list(tuple(int, int)))\n",
      " |  \n",
      " |  tokenize_sents(self, strings)\n",
      " |      Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:\n",
      " |      \n",
      " |          return [self.tokenize(s) for s in strings]\n",
      " |      \n",
      " |      :rtype: list(list(str))\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.tokenize.api.TokenizerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenize.SyllableTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposition every name into alphabets using count vectorizer and performing multinomial naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect=CountVectorizer(analyzer='char',max_features=26)\n",
    "pro=vect.fit_transform(names).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score using method 1: 65.94\n"
     ]
    }
   ],
   "source": [
    "clf=nb.MultinomialNB()\n",
    "clf.fit(pro,np.ravel(y))\n",
    "y_hat=clf.predict(pro)\n",
    "score=1-np.sum(np.not_equal(y_hat,np.ravel(y)))/len(names)\n",
    "print('Score using method 1: %.2f'%(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(name):\n",
    "    word=vect.transform([name]).toarray()\n",
    "    y=clf.predict(word)\n",
    "    if y==0:\n",
    "        print('Female detected!')\n",
    "    else:\n",
    "        print('Male detected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any name.\n",
      "obama\n",
      "Male detected!\n",
      "Enter any name.\n",
      "susan\n",
      "Male detected!\n",
      "Enter any name.\n",
      "michelle\n",
      "Female detected!\n",
      "Enter any name.\n",
      "mikel\n",
      "Female detected!\n",
      "Enter any name.\n",
      "trump\n",
      "Male detected!\n",
      "Enter any name.\n",
      "kanishk\n",
      "Female detected!\n",
      "Enter any name.\n",
      "dany\n",
      "Female detected!\n",
      "Enter any name.\n",
      "\n",
      "Male detected!\n",
      "Enter any name.\n",
      "daniel\n",
      "Female detected!\n",
      "Enter any name.\n",
      "packy\n",
      "Male detected!\n",
      "Enter any name.\n",
      "rachael\n",
      "Female detected!\n",
      "Enter any name.\n",
      "mike\n",
      "Male detected!\n",
      "Enter any name.\n",
      "pompeo\n",
      "Male detected!\n",
      "Enter any name.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    name=input('Enter any name.\\n')\n",
    "    name=name.lower()\n",
    "    if name=='done':\n",
    "        break\n",
    "    classify(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
