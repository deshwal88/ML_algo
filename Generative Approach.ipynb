{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3ef787b6226c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, IntSlider, interact_manual\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.loadtxt('C:/Users/deshw/Downloads/Datasets ML/winery-univariate/wine.data.txt',delimiter=',')\n",
    "features = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "indices=np.random.permutation(178)\n",
    "trainx=data[indices[0:130],1:14]\n",
    "trainy=data[indices[0:130],0]\n",
    "testx=data[indices[130:],1:14]\n",
    "testy=data[indices[130:],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training points per each class: \")\n",
    "for i in range(1,4):\n",
    "    print('{}: '.format(i),eval('sum(trainy=={})'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing points per each class: \")\n",
    "for i in range(1,4):\n",
    "    print('{}: '.format(i),eval('sum(testy=={})'.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Univariate Generative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visualization of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising each class per feature through Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(feature=IntSlider(0,0,12),label=IntSlider(1,1,3))\n",
    "def density_funt(feature,label):\n",
    "    sns.set_style('dark')\n",
    "    mew=np.mean(trainx[trainy==label,feature])\n",
    "    std=np.std(trainx[trainy==label,feature])\n",
    "    n=np.linspace(mew-3*std,mew+3*std,1000)\n",
    "    \n",
    "    plt.hist(trainx[trainy==label,feature],density=True,color=plt.cm.Blues(130))\n",
    "    plt.plot(n,norm.pdf(n,mew,scale=std),'k',lw=2)\n",
    "    \n",
    "    plt.title('Winery {}'.format(label),fontsize=16)\n",
    "    plt.xlabel(str(features[feature]),fontsize=12)\n",
    "    plt.ylabel('Density',fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Gausian Distribution for each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(x,y,feature):\n",
    "    k=set(y)\n",
    "    mew=np.zeros(len(k)+1)\n",
    "    std=np.zeros(len(k)+1)\n",
    "    pi=np.zeros(len(k)+1)\n",
    "    \n",
    "    for i in k:\n",
    "        mew[int(i)]=np.mean(x[y==i,feature])\n",
    "        std[int(i)]=np.std(x[y==i,feature])\n",
    "        pi[int(i)]=sum(y==i)/len(y)\n",
    "    return mew,std,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact(feature=IntSlider(0,0,12))\n",
    "def visual(feature):\n",
    "    sns.set_style('whitegrid')\n",
    "    mean,std,pi=measure(trainx,trainy,feature)\n",
    "    for i in range(1,4):\n",
    "        n=np.linspace(mean[i]-3*std[i],mean[i]+3*std[i],1000)\n",
    "        plt.plot(n,norm.pdf(n,mean[i],scale=std[i]),color=plt.cm.Spectral(i*25),label='Class {0}'.format(i),lw=2.5)\n",
    "    plt.xlabel(features[feature],fontsize=12)\n",
    "    plt.ylabel('Density',fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using test data for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(feature=IntSlider(0,0,12))\n",
    "def predict(feature):\n",
    "    mean,std,pi=measure(trainx,trainy,feature)\n",
    "    k=set(trainy)\n",
    "    label_prob=np.zeros((len(testx),len(k)+1))\n",
    "    for i in range(len(testx)):\n",
    "        for j in k:\n",
    "            label_prob[i,int(j)]=np.log(pi[int(j)]*norm.pdf(testx[i,feature],mean[int(j)],std[int(j)]))\n",
    "    predictions=np.argmax(label_prob[:,1:],axis=1)+1\n",
    "    error=np.not_equal(predictions,testy).sum()/len(testy)\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error comparison among features of Test and Train dataset after prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach(a):\n",
    "    if a=='test_set':\n",
    "        x,y=testx,testy\n",
    "    else:\n",
    "        x,y=trainx,trainy\n",
    "    \n",
    "    error={}\n",
    "    for feature in range(0,12):\n",
    "        mean,std,pi=measure(trainx,trainy,feature)\n",
    "        k=set(trainy)\n",
    "        feature_prob=np.zeros((len(x),len(k)+1))\n",
    "        for i in range(len(x)):\n",
    "            for j in range(1,len(k)+1):\n",
    "                feature_prob[i,j]=np.log(pi[j]*norm.pdf(x[i,feature],mean[j],std[j]))\n",
    "        predictions=np.argmax(feature_prob[:,1:],axis=1)+1\n",
    "        error[feature]=np.not_equal(predictions,y).sum()/len(y)\n",
    "        \n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(12,6))    \n",
    "    plt.plot(list(error.keys()),list(error.values()),marker='o',markersize=4,markerfacecolor='k')\n",
    "    for feature,e in error.items():\n",
    "        plt.text(s=str(format(e,'.3f')),x=feature+0.2,y=e,fontsize=10)\n",
    "    plt.xlabel('Features',fontsize=14)\n",
    "    plt.xlim(-1,13)\n",
    "    plt.ylabel('Error',fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    return sorted(error.items(),key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(approach,a=['test_set','train_set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bivariate Generative Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_bi(x,features):\n",
    "    mean=np.mean(x[:,features],axis=0)\n",
    "    cov=np.cov(x[:,features],bias=True,rowvar=False)\n",
    "    return mean,cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting limit of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limits(x):\n",
    "    width=max(x)-min(x)\n",
    "    upper=max(x)+0.3*width\n",
    "    lower=min(x)-0.3*width\n",
    "    return (upper,lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours(x,feature,mean,cov):\n",
    "    if feature[0]==feature[1]:\n",
    "        print('Choose different value!')\n",
    "        return\n",
    "    x1_up,x1_low=limits(x[:,feature[0]])\n",
    "    x2_up,x2_low=limits(x[:,feature[1]])\n",
    "    x1=np.linspace(x1_low,x1_up,200)\n",
    "    x2=np.linspace(x2_low,x2_up,200)\n",
    "    z=np.zeros((len(x1),len(x2)))\n",
    "    multi=multivariate_normal(mean=mean,cov=cov)\n",
    "    \n",
    "    for i in range(len(x1)):\n",
    "        for j in range(len(x2)):\n",
    "            z[j,i]=multi.logpdf([x1[i],x2[j]])\n",
    "    sign,logdet=np.linalg.slogdet(cov)\n",
    "    normalizer=-0.5*(2*np.log(2*np.pi)+sign*logdet)\n",
    "    for value in range(1,4):\n",
    "        plt.contour(x1,x2,z,levels=[normalizer-value],linestyles='solid',linewidths=1,colors='k')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting contour lines to every feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(feature_1=IntSlider(0,0,12,1),feature_2=IntSlider(6,0,12,1),label=IntSlider(1,1,3,1))\n",
    "def plot(feature_1,feature_2,label):\n",
    "    if feature_1==feature_2:\n",
    "        print('Choose different value!')\n",
    "        return\n",
    "    feature=[feature_1,feature_2]\n",
    "    x=trainx[trainy==label,]\n",
    "    mean,cov=measure_bi(x,feature)\n",
    "    \n",
    "    sns.set_style('white')\n",
    "    contours(x,feature,mean,cov)\n",
    "    plt.scatter(x[:,feature[0]],x[:,feature[1]],color='green',alpha=0.7)\n",
    "    plt.title(str(features[feature_1])+' vs '+str(features[feature_2]),fontsize=14)\n",
    "    plt.xlabel(str(features[feature_1]),fontsize=10)\n",
    "    plt.ylabel(str(features[feature_2]),fontsize=10)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting gaussian for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(x,y,feature):\n",
    "    d=len(feature)\n",
    "    k=len(set(y))\n",
    "    mew=np.zeros((k+1,d))\n",
    "    covar=np.zeros((k+1,d,d))\n",
    "    pi=np.zeros(k+1)\n",
    "    for i in range(1,k+1):\n",
    "        mew[i,:], covar[i,:,:]=measure_bi(x[y==i,],feature)\n",
    "        pi[i]=np.sum([y==i])/len(y)\n",
    "    return mew,covar,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(feature_1=IntSlider(0,0,12,1),feature_2=IntSlider(6,0,12,1))\n",
    "def plot_label(feature_1,feature_2):\n",
    "    if feature_1==feature_2:\n",
    "        print('Choose different value!')\n",
    "        return\n",
    "    \n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(12,8))\n",
    "    feature=[feature_1,feature_2]\n",
    "    mew,covar,pi=fit_model(trainx,trainy,feature)\n",
    "    col=[' ','red','green','blue']\n",
    "    \n",
    "    for label in range(1,4):\n",
    "        mean,cov,pie=mew[label,:],covar[label,:,:],pi[label]\n",
    "        contours(trainx[trainy==label,],feature,mean,cov)\n",
    "        plt.scatter(trainx[trainy==label,feature[0]],trainx[trainy==label,feature[1]],color=plt.cm.Spectral(27*label)\\\n",
    "                   ,label='Class '+str(label))\n",
    "        plt.text(mean[0],mean[1], s=str(label),fontsize=18,fontweight='bold')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title('Bivariate Distribution',fontsize=14,fontweight='bold')\n",
    "    plt.xlabel(str(features[feature_1]),fontsize=12)\n",
    "    plt.ylabel(str(features[feature_2]),fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(f1=IntSlider(0,0,12,1),f2=IntSlider(6,0,12,1),printf=[True,False])\n",
    "def predict(f1,f2,printf):\n",
    "    if f1==f2:\n",
    "        print('Enter a different combination')\n",
    "        return\n",
    "    \n",
    "    feature=[f1,f2]\n",
    "    k=3\n",
    "    score=np.zeros((len(testx),k+1))\n",
    "    mean,cov,pi=fit_model(trainx,trainy,feature)\n",
    "    x=testx[:,feature]\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        for label in range(1,k+1):\n",
    "            multivariate_normal(mean[label,:],cov[label,:,:])\n",
    "            score[i,label]=np.log(pi[label])+multivariate_normal.logpdf(x[i,],mean[label,:],cov[label,:,:])\n",
    "    labels=np.argmax(score[:,1:],axis=1)+1\n",
    "    error=sum(np.not_equal(labels,testy))/len(testy)\n",
    "    if printf:\n",
    "        print('Features used: '+features[f1]+' and '+features[f2])\n",
    "    return error\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors={}  \n",
    "for i in range(0,13):\n",
    "    for j in range(0,13):\n",
    "        index=features[i]+' and '+features[j]\n",
    "        if i==j:\n",
    "            continue\n",
    "        else:\n",
    "            errors[features[i]+' and '+features[j]]=predict(i,j,False)\n",
    "errors=sorted(errors.items(),key=operator.itemgetter(1))\n",
    "print('Feature Combination with min error: '+str(errors[0]))\n",
    "print('Feature Combination with max error: '+str(errors[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we height(z) of the distribution contains only three distint values, i.e. 1,2 or 3. Thus we do not\n",
    "specify position of contours as we did earlier using normalizing term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(f1=IntSlider(0,0,12,1),f2=IntSlider(6,0,12,1))\n",
    "def show_boundaries(f1,f2):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.set_style('whitegrid')\n",
    "    f=[f1,f2]\n",
    "    k=3\n",
    "    x1_lim=limits(trainx[:,f1])\n",
    "    x2_lim=limits(trainx[:,f2])\n",
    "    x1=np.linspace(x1_lim[1],x1_lim[0],350)\n",
    "    x2=np.linspace(x2_lim[1],x2_lim[0],350)\n",
    "    \n",
    "    mean,cov,pi=fit_model(trainx,trainy,f)\n",
    "    z=np.zeros((len(x1),len(x2)))\n",
    "    multi=[multivariate_normal(mean=mean[label,:],cov=cov[label,:,:]) for label in range(1,k+1)]\n",
    "    \n",
    "    \n",
    "    for i in range(len(x1)):\n",
    "        for j in range(len(x2)):\n",
    "            score=[]\n",
    "            for label in range(1,k+1):\n",
    "                score.append(np.log(pi[label])+multi[label-1].logpdf([x1[i],x2[j]]))\n",
    "                \n",
    "            z[j,i]=np.argmax(score)+1\n",
    "            \n",
    "    for label in range(1,k+1):\n",
    "        plt.scatter(trainx[trainy==label,f1],trainx[trainy==label,f2],color=plt.cm.Spectral(label*30),\\\n",
    "                    label='Class '+str(label))\n",
    "    plt.pcolormesh(x1,x2,z)\n",
    "    plt.contour(x1,x2,z,linewidths=0.3,colors='k')\n",
    "    plt.title('Decision Boundaries',fontsize=14,fontweight='bold')\n",
    "    plt.xlabel(features[f1],fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.ylabel(features[f2],fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
