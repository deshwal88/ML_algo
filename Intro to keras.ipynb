{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Regression output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is generated by user from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=np.random.normal(size=(200,3),loc=50,scale=20)\n",
    "y=np.random.uniform(size=(200,1))\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(layers.Dense(5,activation='relu',input_shape=(3,)))\n",
    "model.add(layers.Dense(1,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8fb03adf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=10,validation_split=0.3,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(100,), dtype='int32', name='input')\n",
    "x = tf.keras.layers.Embedding(\n",
    "    output_dim=512, input_dim=10000, input_length=100)(input)\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "dot_img_file = '/tmp/model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used is MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.npy\n",
      "test_labels.npy\n",
      "train_data.npy\n",
      "train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "!ls './Datasets ML/NN_MNIST/MNIST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc='../Datasets ML/NN_MNIST/MNIST/'\n",
    "name=('test_data','test_labels','train_data','train_labels')\n",
    "test_data,test_labels,train_data,train_labels=[np.load(loc+i+'.npy') for i in name]\n",
    "    \n",
    "train_data/=255\n",
    "test_data/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col=train_data.shape[1]\n",
    "n_class=len(set(train_labels))\n",
    "\n",
    "model_1=keras.Sequential()\n",
    "\n",
    "model_1.add(layers.Dense(n_col,activation='relu',input_shape=(n_col,)))\n",
    "model_1.add(layers.Dense(100,activation='relu'))\n",
    "model_1.add(layers.Dense(n_class,activation='softmax'))\n",
    "model_1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 694,950\n",
      "Trainable params: 694,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.9251 - accuracy: 0.7370 - val_loss: 0.4071 - val_accuracy: 0.8720\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 0.9048 - val_loss: 0.3314 - val_accuracy: 0.8996\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2282 - accuracy: 0.9350 - val_loss: 0.2556 - val_accuracy: 0.9236\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1582 - accuracy: 0.9600 - val_loss: 0.2419 - val_accuracy: 0.9284\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1181 - accuracy: 0.9705 - val_loss: 0.2213 - val_accuracy: 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f88290c910>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_data,train_labels,validation_split=0.3,epochs=5,batch_size=250,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.2615 - accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2614990472793579, 0.9259999990463257]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_data,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are used for image processing. The difference is that rather than having distinct hidden layers containing nodes. It contains a number of combinations of convolution and pooling layers set to extract definite features maybe curves and edges, manifolds or simple clasiification according to the requirements. These layers are falttened at the end and fully connected to a hidden dense layer to output a desired outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "model_2=keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(Conv2D(14,(5,5),strides=(1,1),activation='relu'))\n",
    "model_2.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(layers.Dense(100,activation='relu'))\n",
    "model_2.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data.reshape((len(train_data),28,28,1))\n",
    "x_test=test_data.reshape((len(test_data),28,28,1))\n",
    "y_train=to_categorical(train_labels)\n",
    "y_test=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5250 samples, validate on 2250 samples\n",
      "Epoch 1/10\n",
      "5250/5250 [==============================] - 1s 265us/step - loss: 0.0712 - acc: 0.9830 - val_loss: 0.1463 - val_acc: 0.9564\n",
      "Epoch 2/10\n",
      "5250/5250 [==============================] - 2s 305us/step - loss: 0.0605 - acc: 0.9855 - val_loss: 0.1498 - val_acc: 0.9560\n",
      "Epoch 3/10\n",
      "5250/5250 [==============================] - 1s 281us/step - loss: 0.0534 - acc: 0.9878 - val_loss: 0.1350 - val_acc: 0.9591\n",
      "Epoch 4/10\n",
      "5250/5250 [==============================] - 1s 274us/step - loss: 0.0465 - acc: 0.9891 - val_loss: 0.1404 - val_acc: 0.9591\n",
      "Epoch 5/10\n",
      "5250/5250 [==============================] - 2s 286us/step - loss: 0.0375 - acc: 0.9930 - val_loss: 0.1286 - val_acc: 0.9600\n",
      "Epoch 6/10\n",
      "5250/5250 [==============================] - 1s 284us/step - loss: 0.0315 - acc: 0.9941 - val_loss: 0.1241 - val_acc: 0.9636\n",
      "Epoch 7/10\n",
      "5250/5250 [==============================] - 1s 281us/step - loss: 0.0283 - acc: 0.9954 - val_loss: 0.1258 - val_acc: 0.9627\n",
      "Epoch 8/10\n",
      "5250/5250 [==============================] - 1s 277us/step - loss: 0.0233 - acc: 0.9966 - val_loss: 0.1211 - val_acc: 0.9631\n",
      "Epoch 9/10\n",
      "5250/5250 [==============================] - 1s 283us/step - loss: 0.0216 - acc: 0.9968 - val_loss: 0.1208 - val_acc: 0.9653\n",
      "Epoch 10/10\n",
      "5250/5250 [==============================] - 1s 277us/step - loss: 0.0165 - acc: 0.9981 - val_loss: 0.1242 - val_acc: 0.9627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8b8c3c088>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train,y_train,validation_split=0.3, epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 14)        364       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               201700    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 203,074\n",
      "Trainable params: 203,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 134us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18043343287706376, 0.95]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
